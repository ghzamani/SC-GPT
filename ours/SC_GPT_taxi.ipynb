{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qLj9CvenFBl"
      },
      "source": [
        "# Mount Google Drive and installing requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz3JzdaZ-1CQ",
        "outputId": "b6d23f04-fb6c-4ddd-d19c-c399fb6ea9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4klI-Lg-3II",
        "outputId": "6f709b86-27ea-47b1-ede7-e5101669cb9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SC_GPT\n"
          ]
        }
      ],
      "source": [
        "%cd 'drive/MyDrive/SC_GPT'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHrv3xKBAKOA",
        "outputId": "56dd1dbf-10fc-44f0-f816-61e7174ea1d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (7.2.2)\n",
            "Collecting sacremoses (from -r requirements.txt (line 3))\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.0.1+cu118)\n",
            "Collecting ftfy (from -r requirements.txt (line 6))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.10.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.5.4)\n",
            "Collecting sentencepiece (from -r requirements.txt (line 10))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.7.1)\n",
            "Collecting botocore (from -r requirements.txt (line 14))\n",
            "  Downloading botocore-1.31.3-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl_py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (5.9.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2022.10.31)\n",
            "Collecting boto3 (from -r requirements.txt (line 19))\n",
            "  Downloading boto3-1.28.3-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting apex (from -r requirements.txt (line 20))\n",
            "  Downloading apex-0.9.10dev.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fairseq (from -r requirements.txt (line 21))\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting GitPython (from -r requirements.txt (line 22))\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (0.42.1)\n",
            "Collecting mock (from -r requirements.txt (line 24))\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Collecting ptvsd (from -r requirements.txt (line 25))\n",
            "  Downloading ptvsd-4.3.2-py2.py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pythainlp (from -r requirements.txt (line 26))\n",
            "  Downloading pythainlp-4.0.2-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit_learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.2.2)\n",
            "Collecting seqeval (from -r requirements.txt (line 28))\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorboardX (from -r requirements.txt (line 29))\n",
            "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (2.12.0)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (4.9.2)\n",
            "Collecting transformers (from -r requirements.txt (line 32))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 1)) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 2)) (1.1.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 5)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 5)) (16.0.6)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 6)) (0.2.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (2.0.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (6.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (1.10.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 9)) (3.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 12)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 12)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 12)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (2.8.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore->-r requirements.txt (line 14))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->-r requirements.txt (line 19))\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptacular (from apex->-r requirements.txt (line 20))\n",
            "  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zope.sqlalchemy (from apex->-r requirements.txt (line 20))\n",
            "  Downloading zope.sqlalchemy-3.0-py3-none-any.whl (23 kB)\n",
            "Collecting velruse>=1.0.3 (from apex->-r requirements.txt (line 20))\n",
            "  Downloading velruse-1.1.1.tar.gz (709 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyramid>1.1.2 (from apex->-r requirements.txt (line 20))\n",
            "  Downloading pyramid-2.0.1-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyramid_mailer (from apex->-r requirements.txt (line 20))\n",
            "  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting wtforms (from apex->-r requirements.txt (line 20))\n",
            "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.5/136.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wtforms-recaptcha (from apex->-r requirements.txt (line 20))\n",
            "  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 21)) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 21)) (0.29.36)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->-r requirements.txt (line 21))\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq->-r requirements.txt (line 21))\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->-r requirements.txt (line 21))\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from fairseq->-r requirements.txt (line 21))\n",
            "  Downloading bitarray-2.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.6/273.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 21)) (2.0.2+cu118)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython->-r requirements.txt (line 22))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn->-r requirements.txt (line 27)) (3.1.0)\n",
            "Collecting protobuf>=4.22.3 (from tensorboardX->-r requirements.txt (line 29))\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (1.56.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 30)) (0.32.0)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->-r requirements.txt (line 31)) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->-r requirements.txt (line 31)) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->-r requirements.txt (line 31)) (1.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->-r requirements.txt (line 31)) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->-r requirements.txt (line 31)) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->-r requirements.txt (line 31)) (0.10.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers->-r requirements.txt (line 32))\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 32)) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 32))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 32))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 30)) (0.40.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets->-r requirements.txt (line 31)) (6.0.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets->-r requirements.txt (line 31)) (3.16.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython->-r requirements.txt (line 22))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->-r requirements.txt (line 32)) (2023.6.0)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->-r requirements.txt (line 21))\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->-r requirements.txt (line 30)) (0.2.0)\n",
            "Collecting hupper>=1.5 (from pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading hupper-1.12-py3-none-any.whl (22 kB)\n",
            "Collecting plaster (from pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting plaster-pastedeploy (from pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting translationstring>=0.4 (from pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
            "Collecting venusian>=1.0 (from pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading venusian-3.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting webob>=1.8.3 (from pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.deprecation>=3.5.0 (from pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\n",
            "Collecting zope.interface>=3.8.0 (from pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 21))\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 21)) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 21))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 21)) (4.9.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (2.3.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 9)) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 9)) (0.1.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from velruse>=1.0.3->apex->-r requirements.txt (line 20)) (1.3.1)\n",
            "Collecting anykeystore (from velruse>=1.0.3->apex->-r requirements.txt (line 20))\n",
            "  Downloading anykeystore-0.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python3-openid (from velruse>=1.0.3->apex->-r requirements.txt (line 20))\n",
            "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->-r requirements.txt (line 21)) (2.21)\n",
            "Collecting pbkdf2 (from cryptacular->apex->-r requirements.txt (line 20))\n",
            "  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.3)\n",
            "Collecting repoze.sendmail>=4.1 (from pyramid_mailer->apex->-r requirements.txt (line 20))\n",
            "  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transaction (from pyramid_mailer->apex->-r requirements.txt (line 20))\n",
            "  Downloading transaction-3.1.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r requirements.txt (line 31)) (1.59.1)\n",
            "Requirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from zope.sqlalchemy->apex->-r requirements.txt (line 20)) (2.0.18)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (4.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex->-r requirements.txt (line 20)) (3.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex->-r requirements.txt (line 20)) (2.0.2)\n",
            "Collecting PasteDeploy>=2.0 (from plaster-pastedeploy->pyramid>1.1.2->apex->-r requirements.txt (line 20))\n",
            "  Downloading PasteDeploy-3.0.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from python3-openid->velruse>=1.0.3->apex->-r requirements.txt (line 20)) (0.7.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 30)) (0.5.0)\n",
            "Building wheels for collected packages: sacremoses, apex, fairseq, seqeval, antlr4-python3-runtime, velruse, cryptacular, anykeystore, pbkdf2\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=ee71a6e5e5c8b40d890becf792f48b4af16342903b1259c6925a2622778a0151\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46443 sha256=cb5f671534c95b2071405ce34f70f3a7365bb61337d0aae33b196dbb032af905\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/62/59/9b100fce7ebd989603b3b7a4ca259150da72c9e107fcaa2a30\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11171313 sha256=c9a7aa5b8319e7f62831afbe6e1fd3f5b175801526d989651870f73a7485f6de\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=9a1cdada4d138acbc9a8eda7978e5a67c300bb65d71a634ca0a3e290c542bd30\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=a013e1949eb13115b3b1c5fa6eee7a9057b777e04698267bf6f6105e3808437d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50910 sha256=015d8632be9b09151c4f1cb6043b5b5eb5368c0e59596d582be903504772239a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/f9/a4/fc4ea7b935ee9c58b9bc772cabd94f6a8560f35444097d948d\n",
            "  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp310-cp310-linux_x86_64.whl size=58181 sha256=c4eddc4d24ad3ef4d80a1e4da04fb246793d3b44ce61a7de6f0ee2cd791124ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/6e/09/a7fba517f95b2a6a36bd01b6d4f4679fa7259615a493b64b8f\n",
            "  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16814 sha256=5d3f3bc9de11a65e0e97d594117299d571fec5942fd79014054e79d42510f2cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/9e/24/35542b7d376b53a6f8426524cc5a3f7998f975037b32d19906\n",
            "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5081 sha256=8080e5321b26b1442030de8f948aef41248c6552f7d28b73c0af81a4a6191f7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/7d/8b/4269ff90fda80497ec59f6ff7d1e1596cb697c1dc8e9bbe320\n",
            "Successfully built sacremoses apex fairseq seqeval antlr4-python3-runtime velruse cryptacular anykeystore pbkdf2\n",
            "Installing collected packages: translationstring, tokenizers, sentencepiece, safetensors, pbkdf2, bitarray, anykeystore, antlr4-python3-runtime, zope.interface, zope.deprecation, wtforms, webob, venusian, smmap, sacremoses, python3-openid, ptvsd, protobuf, portalocker, plaster, PasteDeploy, omegaconf, mock, jmespath, hupper, ftfy, cryptacular, colorama, wtforms-recaptcha, transaction, tensorboardX, sacrebleu, pythainlp, plaster-pastedeploy, hydra-core, huggingface-hub, gitdb, botocore, zope.sqlalchemy, transformers, seqeval, s3transfer, repoze.sendmail, pyramid, GitPython, velruse, pyramid_mailer, boto3, apex, fairseq\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed GitPython-3.1.32 PasteDeploy-3.0.1 antlr4-python3-runtime-4.8 anykeystore-0.2 apex-0.9.10.dev0 bitarray-2.7.6 boto3-1.28.3 botocore-1.31.3 colorama-0.4.6 cryptacular-1.6.2 fairseq-0.12.2 ftfy-6.1.1 gitdb-4.0.10 huggingface-hub-0.16.4 hupper-1.12 hydra-core-1.0.7 jmespath-1.0.1 mock-5.1.0 omegaconf-2.0.6 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 portalocker-2.7.0 protobuf-4.23.4 ptvsd-4.3.2 pyramid-2.0.1 pyramid_mailer-0.15.1 pythainlp-4.0.2 python3-openid-3.2.0 repoze.sendmail-4.4.1 s3transfer-0.6.1 sacrebleu-2.3.1 sacremoses-0.0.53 safetensors-0.3.1 sentencepiece-0.1.99 seqeval-1.2.2 smmap-5.0.0 tensorboardX-2.6.1 tokenizers-0.13.3 transaction-3.1.0 transformers-4.30.2 translationstring-1.4 velruse-1.1.1 venusian-3.0.0 webob-1.8.7 wtforms-3.0.1 wtforms-recaptcha-0.3.2 zope.deprecation-5.0 zope.interface-6.0 zope.sqlalchemy-3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5He1C-Lc5RDp"
      },
      "source": [
        "# Fetch and unzip the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7nZkT2rasYf",
        "outputId": "4986f413-57d2-464f-c2ef-ae9d8fd32d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
            "Git LFS initialized.\n",
            "Cloning into 'scgpt'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 16\u001b[K\n",
            "Unpacking objects: 100% (16/16), 538.98 KiB | 1.09 MiB/s, done.\n",
            "fatal: cannot exec '/content/drive/MyDrive/SC_GPT/scgpt/.git/hooks/post-checkout': Permission denied\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/metehergul/scgpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmrZIZmKTTKs"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgVpgjHNdSwP",
        "outputId": "00134879-2eb3-4889-c3fc-c3fe406b6b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-17 06:38:04.957295: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-17 06:38:06.233419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/17/2023 06:38:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "07/17/2023 06:38:35 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='data/taxi/train.txt', output_dir='MODEL_SAVE_PATH', eval_data_file='data/taxi/train.txt', model_type='gpt2', model_name_or_path='./scgpt', mlm=False, mlm_probability=0.15, config_name='', tokenizer_name='', cache_dir='', block_size=80, do_train=True, do_eval=True, evaluate_during_training=False, do_lower_case=False, per_gpu_train_batch_size=1, per_gpu_eval_batch_size=1, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=20.0, max_steps=-1, warmup_steps=0, logging_steps=100, save_steps=5000, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=True, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', text_chunk=False, use_reverse=False, with_code_loss=True, use_tokenize=True, max_seq=80, n_gpu=1, device=device(type='cuda'))\n",
            "07/17/2023 06:38:36 - INFO - __main__ -   Creating features from dataset file at data/taxi\n",
            "07/17/2023 06:38:37 - INFO - __main__ -   Saving features into cached file data/taxi/MODEL_SAVE_PATH_cached_lm_80_seqlen_80_train.txt\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "07/17/2023 06:38:37 - INFO - __main__ -   ***** Running training *****\n",
            "07/17/2023 06:38:37 - INFO - __main__ -     Num examples = 40\n",
            "07/17/2023 06:38:37 - INFO - __main__ -     Num Epochs = 20\n",
            "07/17/2023 06:38:37 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
            "07/17/2023 06:38:37 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "07/17/2023 06:38:37 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "07/17/2023 06:38:37 - INFO - __main__ -     Total optimization steps = 800\n",
            "1 / 20 Epoch: 100% 40/40 [00:11<00:00,  3.56it/s]\n",
            "2 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.67it/s]\n",
            "3 / 20 Epoch:  48% 19/40 [00:03<00:04,  4.93it/s]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "07/17/2023 06:39:01 - INFO - __main__ -     EVALERR:  0.7172863922268152\n",
            "3 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.88it/s]\n",
            "4 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.62it/s]\n",
            "5 / 20 Epoch:  98% 39/40 [00:07<00:00,  4.71it/s]07/17/2023 06:39:22 - INFO - __main__ -     EVALERR:  0.46942678328603504\n",
            "5 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.88it/s]\n",
            "6 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.66it/s]\n",
            "7 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.87it/s]\n",
            "8 / 20 Epoch:  48% 19/40 [00:04<00:04,  4.35it/s]07/17/2023 06:39:43 - INFO - __main__ -     EVALERR:  0.36367527954280376\n",
            "8 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.51it/s]\n",
            "9 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.86it/s]\n",
            "10 / 20 Epoch:  98% 39/40 [00:08<00:00,  4.88it/s]07/17/2023 06:40:04 - INFO - __main__ -     EVALERR:  0.27290145102888347\n",
            "10 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.65it/s]\n",
            "11 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.70it/s]\n",
            "12 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.63it/s]\n",
            "13 / 20 Epoch:  48% 19/40 [00:03<00:04,  4.85it/s]07/17/2023 06:40:25 - INFO - __main__ -     EVALERR:  0.21630770359188317\n",
            "13 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.78it/s]\n",
            "14 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.61it/s]\n",
            "15 / 20 Epoch:  98% 39/40 [00:08<00:00,  4.60it/s]07/17/2023 06:40:47 - INFO - __main__ -     EVALERR:  0.20791786912828683\n",
            "15 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.75it/s]\n",
            "16 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.61it/s]\n",
            "17 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.71it/s]\n",
            "18 / 20 Epoch:  48% 19/40 [00:04<00:04,  4.42it/s]07/17/2023 06:41:08 - INFO - __main__ -     EVALERR:  0.17024746548384428\n",
            "18 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.61it/s]\n",
            "19 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.74it/s]\n",
            "20 / 20 Epoch:  98% 39/40 [00:08<00:00,  4.81it/s]07/17/2023 06:41:30 - INFO - __main__ -     EVALERR:  0.16780858878046273\n",
            "20 / 20 Epoch: 100% 40/40 [00:08<00:00,  4.62it/s]\n",
            "07/17/2023 06:41:30 - INFO - __main__ -    global_step = 800, average loss = 0.3231964416336268\n",
            "07/17/2023 06:41:30 - INFO - __main__ -   Saving model checkpoint to MODEL_SAVE_PATH\n",
            "07/17/2023 06:41:45 - INFO - __main__ -   Evaluate the following checkpoints: ['MODEL_SAVE_PATH']\n",
            "07/17/2023 06:41:54 - INFO - __main__ -   Creating features from dataset file at data/taxi\n",
            "07/17/2023 06:41:54 - INFO - __main__ -   Saving features into cached file data/taxi/MODEL_SAVE_PATH_cached_lm_80_seqlen_80_train.txt\n",
            "07/17/2023 06:41:54 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "07/17/2023 06:41:54 - INFO - __main__ -     Num examples = 40\n",
            "07/17/2023 06:41:54 - INFO - __main__ -     Batch size = 1\n",
            "Evaluating: 100% 40/40 [00:01<00:00, 21.85it/s]\n",
            "07/17/2023 06:41:56 - INFO - __main__ -   ***** Eval results  *****\n",
            "07/17/2023 06:41:56 - INFO - __main__ -     perplexity = tensor(1.1104)\n"
          ]
        }
      ],
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0\n",
        "!python train.py --output_dir=MODEL_SAVE_PATH --model_type=gpt2 --model_name_or_path='./scgpt' --do_train --do_eval --eval_data_file=data/taxi/train.txt --per_gpu_train_batch_size 1 --num_train_epochs 20 --learning_rate 1e-5 --overwrite_cache --use_tokenize --train_data_file=data/taxi/train.txt --overwrite_output_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29zXJaOzTc25"
      },
      "source": [
        "# Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex7ZZO1XTd11",
        "outputId": "c9a8cdfb-f3ab-4d90-ebc3-03238099e0d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading (…)lve/main/config.json: 100% 665/665 [00:00<00:00, 3.84MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 656/656 [00:00<00:00, 3.46MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 760/760 [00:00<00:00, 3.83MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 856/856 [00:00<00:00, 5.30MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 615/615 [00:00<00:00, 3.84MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 635/635 [00:00<00:00, 3.01MB/s]\n",
            "07/17/2023 06:42:25 - INFO - __main__ -   Namespace(model_type='gpt2', model_name_or_path='MODEL_SAVE_PATH', prompt='', padding_text='', xlm_lang='', length=80, num_samples=5, temperature=1.0, repetition_penalty=1.0, top_k=0, top_p=0.9, no_cuda=False, seed=42, stop_token=None, input_file='data/taxi/test.txt', output_file='results.json', nc=1, use_token=False, device=device(type='cuda'), n_gpu=1)\n",
            "  0% 0/47 [00:00<?, ?it/s]2023-07-17 06:42:36.827355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/17/2023 06:42:38 - INFO - numexpr.utils -   NumExpr defaulting to 2 threads.\n",
            "100% 47/47 [05:15<00:00,  6.71s/it]\n"
          ]
        }
      ],
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0\n",
        "# !python generate.py --model_type=gpt2 --model_name_or_path=MODEL_SAVE_PATH --num_samples 5 --input_file=data/restaurant/test.txt --top_k 5 --output_file=results.json --length 80\n",
        "!python generate.py --model_type=gpt2 --model_name_or_path=MODEL_SAVE_PATH --num_samples 5 --input_file=data/taxi/test.txt --top_p 0.9 --output_file=results.json --length 80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfS3fO5kTnNV"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LABup8r1Nq9y",
        "outputId": "bffe07d0-3483-47b9-9124-e42328866051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SvjQT0xTpAe",
        "outputId": "a8b3935b-3c98-4e08-8baa-3d70ff4996fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##############################################\n",
            "BLEU SCORE & SLOT ERROR on GENERATED SENTENCES\n",
            "##############################################\n",
            "Metric       :\tBLEU\tT.ERR\tA.ERR\n",
            "HDC          :\t1.0000\t0.00%\t0.00%\n",
            "Ref          :\t1.0000\t0.70%\t0.30%\n",
            "----------------------------------------------\n",
            "This Model   :\t0.1384\t3.70%\t1.80%\n",
            "FIELNAME: results.json, BLEU: 0.1384151912112596, ERR:3.6973131736526946\n"
          ]
        }
      ],
      "source": [
        "!python evaluator.py --domain taxi --target_file results.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3923WyEjTqP1"
      },
      "source": [
        "# Interact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7DXWQV6Tuh3",
        "outputId": "531d5241-522a-477b-b41c-f85606557f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/12/2023 17:45:33 - INFO - __main__ -   Namespace(model_type='gpt2', model_name_or_path='MODEL_SAVE_PATH', prompt='', padding_text='', xlm_lang='', length=50, num_samples=5, temperature=1.0, repetition_penalty=1.0, top_k=0, top_p=0.9, no_cuda=False, seed=42, stop_token=None, device=device(type='cuda'), n_gpu=1)\n",
            "Model prompt >>> \n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python interact.py --model_type=gpt2 --model_name_or_path=MODEL_SAVE_PATH --length 50 --num_samples 5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-qLj9CvenFBl",
        "3923WyEjTqP1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}