# SC-GPT
This repository contains some experiments conducted on [SC-GPT model](https://github.com/pengbaolin/SC-GPT), to reproduce the results. SC-GPT was introduced in [Few-shot Natural Language Generation for Task-Oriented Dialog](https://arxiv.org/abs/2002.12328). It is pre-trained on a large set of annotated NLG corpus to acquire the controllable generation ability, and fine-tuned with only a few domain-specific labels to adapt to new domains.

Also, we tried to improve the results, by using T5 as the base model instead of GPT-2.
